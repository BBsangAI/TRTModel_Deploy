## 2024/10/16
### USB摄像头0实时采集图像，python通过opencv的gstreamer接口拉取视频流，再写入共享内存（加入信号量和互斥锁） 
     --数据格式： 3 x 16 x 112 x 112

     --进度1： tensorrt.cpp读取engine模型文件,使用模型进行推理（到创建buffer）

     --进度2： image_pretrain.cpp 访问共享内存，将图片数据映射到本地，使用std::vector<cv::Mat>存放。

## 2024/10/17-v1

###  可以实现拉取视频流到推理全过程，但是推理结果不正确，考虑是视频流拉取的问题，没有获取到真正实时的共享内存中的数据。
     --调试1： 将获取到的图片保存到本地查看，结果全是黑色（正则化之后未将数据乘回去）
     --调试2： 图片显示黑白色的九宫格样子
     --调试3： 图片维度错了，改成112 x 112 x 3图片数据问题解决了。
     
## 2024/10/17-v2
### 可以从共享内存中读取并保存图片，正常显示。但是推理结果不好，基本都是一个结果就是数值大小不同。
     --调试1： 考虑还是图片数据维度不对，虽然保存后可以正常显示，但是这里图片的维度是（32x112x112x3）而模型要求输入的是（32x3x112x112）

## 2024/10/18-v1
     --调试1： opencv获取到的图像是16*112*112*3的，在送入推理引擎之前，把图像数据转成3*16*112*112（模型要求的输入），在数据没大问题的情况下（摄像头采集角度，采集时间）
               推理结果似乎能看出来是正确的。
     --调试2： 摆正角度并且把控好时间，准确率不错，目前问题是分类器的激活时间很难把控，解决方案是加一个软件开关，用来捕获手势动作的开始。

## 2024/10/22-v1
     --调试1： 修改了TensorRT推理引擎的定义，封装成了一个类，可以支持各种不同的模型输入以及输出。
               可以连续进行手势检测器和手势分类器的任务，暂未整合在一起。预设计两个进程，相互激活。
          
## 2024/10/23-v1
     --调试1： 增加了Params.h,封装了线程参数结构体，定义了分类名称字典。
     --调试2： 将检测和分类分为两个线程，检测到手势，用条件变量通知手势分类线程，共享内存的方式通知python进程。
               python进程判断到检测到手势，改为写入16帧（原来是2帧）。
     --未解决问题1：未做到同步，当python进程接收到检测到手势信号，当前写入帧数暂未改变，但是分类线程预接收图像帧数已经改变
                   造成报错。
     --未解决问题2：共享内存的方式通知不知道效率和实时性如何，python中检测到手势之后写入帧数不是单次改变，而是一直改变。

## 2024/10/24-v1
### 基本完成实时检测和分类任务，检测到手势后存储后16帧图像，单次激活分类器进行动态手势分类。但是分类效果不好，训练出的模型鲁棒性不好。
     --问题解决： 检测到手势之后将线程挂起一段时间，再等待分类完成。 
                  将手势检测和手势分类分为两个共享内存，因为所用到的空间大小不一样
